var documenterSearchIndex = {"docs":
[{"location":"guide/#Guide","page":"Guide","title":"Guide","text":"","category":"section"},{"location":"guide/","page":"Guide","title":"Guide","text":"","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"The following guide provides information on how to install and use the RunStatistics.jl package and the functions it provides, and on some of their implementation. ","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"Pages = [\"guide.md\"]\nDepth = 3","category":"page"},{"location":"guide/#Installation","page":"Guide","title":"Installation","text":"","category":"section"},{"location":"guide/","page":"Guide","title":"Guide","text":"","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"To install RunStatistics.jl, start Julia and run ","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> using Pkg\njulia> pkg\"add RunStatistics\"","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"To use RunStatistics.jl after installation, run ","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> using RunStatistics","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"to gain access to the functions provided in the package.","category":"page"},{"location":"guide/#Using-RunStatistics.jl","page":"Guide","title":"Using RunStatistics.jl","text":"","category":"section"},{"location":"guide/","page":"Guide","title":"Guide","text":"","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"To use the RunStatistics.jl to calculate and interpret the Squares statistic for the data you observed, first make sure it satisfies these conditions:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"All observations X_i are independent. \nEach observation is normally distributed, X_i sim mathcalN(mu_i sigma^2_i)\nMean mu_i and variance sigma^2_i are known.","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"If your data satisfies these conditions, bring it into the form of an array X of length N, so that X[i] contains the i-th observation.","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"To obtain the p-value for the value of the Squares statistic observed in your data, do this:","category":"page"},{"location":"guide/#Calculate-T_{obs}","page":"Guide","title":"Calculate T_obs","text":"","category":"section"},{"location":"guide/","page":"Guide","title":"Guide","text":"To obtain the value of the Squares statistic T observed in the data, T_obs, do:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> t_obs(X, μ, σ2)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"where mu and sigma 2 are the mean and variance of the normal distribution the data follows.","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"t_obs() returns a tuple containing the desired value T_obs as well as one or more arrays containing the indices i of the observations X_i in the run(s) that produce T_obs. (It is generally possible that more than one run produces the same value for T.)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"In case the observations X_i have individual expectations and variances, do:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> t_obs(X, μ, σ2)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"But with mu and sigma 2 being Arrays where mui and sigma 2i are the mean and variance of the i-th element of X. ","category":"page"},{"location":"guide/#Calculate-the-p-value,-Evaluate-the-cumulative-distribution-function-of-T","page":"Guide","title":"Calculate the p-value, Evaluate the cumulative distribution function of T","text":"","category":"section"},{"location":"guide/","page":"Guide","title":"Guide","text":"To obtain the exact p-value given the value of T_obs for N lesssim 100 data points, or evaluate the cumulative distribution function of T do:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> squares_pvalue(T_obs, N)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"or","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> squares_cdf(T_obs, N)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"In case the number L of observations in the data set exceeds L gtrsim 100, do:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> squares_pvalue_approx(T_obs, L)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"or","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> squares_cdf_approx(T_obs, L)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"To obtain the approximation for the p-value or the cumulative.","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"It is possible to control the approximation more accurately with additional methods and optional input arguments. See Approximation for large numbers of data below for more information.","category":"page"},{"location":"guide/#Details-of-computation","page":"Guide","title":"Details of computation","text":"","category":"section"},{"location":"guide/","page":"Guide","title":"Guide","text":"","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"In the following some more in-depth information on the calculations performed with RunStatistics.jl is given.","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"As during the derivation of the p-value for T in [1], the quantity that is being computed here is ","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"P(T  T_obs  N)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"This is the value of the cumulative distribution function of T at the value T_obs observed in a sequence of N datapoints. ","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"The p-value then is obtained as p = 1- P(T  T_obs  N).","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"The central calculation in this package implements Equation (16) from [1]:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"P(T  T_obs  N) = sum_r = 1^Nsum_M = 1^M_maxsum_pi X(T_obs N)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"The full derivation of P(T  T_obs  N) and an explanation for the parameters in the above equation can be found in section 2 of [1]. ","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"For this manual, suffice it to say that the only input parameters that need to be known are T_obs and N, the total number of observed data points. The other parameters are then calculated from them.","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"The computationally expensive operation is the sum over pi. Here pi denotes the set of inequivalent sequences of success and failure runs in the observed sequence of data. Given a total number r of successes in a sequence of N observations with M success runs, pi is in one-to-one correspondence with the set of integer partitions of r into M summands [2].","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"When the cumulative of T is evaluated at T_obs for N data points, the relevant partitions need to be calculated.","category":"page"},{"location":"guide/#Partitions","page":"Guide","title":"Partitions","text":"","category":"section"},{"location":"guide/","page":"Guide","title":"Guide","text":"","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"In this package, a partition of an integer n into k parts is represented with a Partition() object. It holds the fields:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"n::Int   \nk::Int\nh::Int          Number of *distinct* parts\nc::Vector{Int}  Multiplicities of parts\ny::Vector{Int}  parts","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"With these parameters, a partition can be represented in the multiplicity representation:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"beginalign\nn = sum_i = 2^h + 1 c_i cdot y_i\nendalign","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"It is important to note the indexing of the arrays holding the parts and their multiplicities. Due to the implementation of the algorithm used to generate partitions, the first elements of c and y hold a buffer value, and the arrays always have a length of 1 + the maximum possible number of parts.","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"So when reading a partition, always use the above equation: ignore the first element of c and y and do not read beyond c[h + 1] and y[h + 1].","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"To save memory during the evaluation of the cumulative, a partition object is initiated and updated in place during the summation over the set of possible partitions.","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"The function that updates a partition is next_partition!() it implements a modified version of Algorithm Z from ","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"A. Zoghbi: Algorithms for generating integer partitions, Ottawa (1993). ","category":"page"},{"location":"guide/#Approximation-for-large-numbers-of-data","page":"Guide","title":"Approximation for large numbers of data","text":"","category":"section"},{"location":"guide/","page":"Guide","title":"Guide","text":"","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"As discussed in the Introduction the method for approximating the value of the cumulative for large numbers L of observations involves splitting L into n sequences containing N observations. ","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"The original paper's[2] authors have tested different combinations of n and N and found that they agree up to nine significant digits.","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"The default values in this package are N = 80 and n = L  N, but user defined choices can also be used by calling:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> squares_pvalue_approx(T_obs, Ns)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"or","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> squares_cdf_approx(T_obs, Ns)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"Where Ns is an array containing N::Integer and n::Real as its first and second entry: Ns = [N, n].","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"n does not need to be an integer.","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"For these approximations, this package implements equation (17) from [2]:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"beginalign\nF(T_obs  nN) = fracF(T_obs  N)^n(1 + Delta(T_obs))^n-1 quad textfor quad nge 2\nendalign","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"F(T_obs  L) equiv P(T  T_obs  L) denotes the value of the cumulative of T for a (long) sequence of L observations. ","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"So, if a total number of L data points have been observed, choose n and N so that n cdot N = L. The exact value of F(T_obs  N) equiv P(T  T_obs  N) is then calculated and further processed in accordance with the above equation.","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"The approximate p-value for the data set then is:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"beginalign\np = 1 - F(T_obs  nN)\nendalign","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"Delta(T_obs) is a correction term (see equation (13) in [2]) whose computation involves a 1D numerical integration. This is performed with the quadgk() function from the QuadGK.jl package.","category":"page"},{"location":"guide/#Accuracy","page":"Guide","title":"Accuracy","text":"","category":"section"},{"location":"guide/","page":"Guide","title":"Guide","text":"","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"The precision of the Approximation of F(T  nN) can be evaluated as:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"beginalign\ndF(T  nN) leq n  dF(T  N) oplus (1 - n)  dDelta(T)\nendalign","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"where oplus indicates addition in quadrature (See section C of [2]). ","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"To reach a given precision epsilon on p or F(T  nN), it is required that F(T  N) and Delta(T) are evaluated to an absolute precision epsilonn. The calculation of F(T  N) is performed to double floating point precision, so up to an absolute precision of at least 10^-15, which limits the possible precision of p and F(T  nN).","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"As an example, for L = 10^6, N = 100, and epsilon = 10^5, we would need an absolute precision on F(T  N) and Delta(T) at the 10^9 level.","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"To assure this level is reached, the additional argument epsp in the squares_pvalue_approx() and squares_cdf_approx() functions can be specified:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> squares_pvalue_approx(T_obs, L, epsp)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"or","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> squares_cdf_approx(T_obs, L, epsp)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"This call yields a conservative approximation by setting the absolute error tolerance of the 1D integration that yields Delta(T) to be one order of magnitude greater than necessary for the desired accuracy epsp of p or the cumulative. If not specified, the default value of the quadgk() function used for the integration is used. See documentation.","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"Rule of thumb: to obtain a quick approximation of p or F(T  nN), call:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> squares_pvalue_approx(T_obs, L)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"or","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> squares_cdf_approx(T_obs, L)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"And if a certain accuracy epsp geq n cdot 10^-14 is desired, call:","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> squares_pvalue_approx(T_obs, L, epsp)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"or","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"julia> squares_cdf_approx(T_obs, L, epsp)","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"[1]: Frederik Beaujean and Allen Caldwell. A Test Statistic for Weighted Runs. Journal of Statistical Planning and Inference 141, no. 11 (November 2011): 3437–46. doi:10.1016/j.jspi.2011.04.022 arXiv:1005.3233","category":"page"},{"location":"guide/","page":"Guide","title":"Guide","text":"[2]: Frederik Beaujean and Allen Caldwell. Is the bump significant? An axion-search example arXiv:1710.06642","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#Modules","page":"API","title":"Modules","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Order = [:module]","category":"page"},{"location":"api/#Types-and-constants","page":"API","title":"Types and constants","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Order = [:type, :constant]","category":"page"},{"location":"api/#Functions-and-macros","page":"API","title":"Functions and macros","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Order = [:macro, :function]","category":"page"},{"location":"api/#Documentation","page":"API","title":"Documentation","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [RunStatistics]\nOrder = [:module, :type, :constant, :macro, :function]","category":"page"},{"location":"api/#RunStatistics.RunStatistics","page":"API","title":"RunStatistics.RunStatistics","text":"This package implements the evaluation of the cumulative distribution function of the Squares test statistic originally defined in\n\nFrederik Beaujean and Allen Caldwell. A Test Statistic for Weighted Runs.\n\nhttps://arxiv.org/abs/1005.3233\n\nThe authors further derived an approximation to be able to compute the cumulative also for large numbers of observations in\n\nFrederik Beaujean and Allen Caldwell. Is the bump significant? An axion-search example \n\nhttps://arxiv.org/abs/1710.06642 \n\nWhere they renamed the weighted-runs statistic to the *Squares statistic*. This code is based on the original implementation by Frederik Beaujean in c++ and mathematica:\n\nhttps://github.com/fredRos/runs\n\n\n\n\n\n","category":"module"},{"location":"api/#RunStatistics.IntegrandData","page":"API","title":"RunStatistics.IntegrandData","text":"IntegrandData\n\nRepresent the parameters needed for the 1D numerical integration performed in Delta().\n\nT_obs is the value for the Squares statistic observed in the data, Nl the left-hand length and  Nr the right-hand length of a boundary spanning run, as defined in section II.A. in\n\nFrederik Beaujean and Allen Caldwell. Is the bump significant? An axion-search example\n\nhttps://arxiv.org/abs/1710.06642\n\n\n\n\n\n","category":"type"},{"location":"api/#RunStatistics.IntegrandData-Tuple{Real}","page":"API","title":"RunStatistics.IntegrandData","text":"(integrand::IntegrandData)(x::Real)\n\nCompute the integrand in the Δ(Tobs | Nl, N_r) term defined in equation (13) in \n\nFrederik Beaujean and Allen Caldwell. Is the bump significant? An axion-search example\n\nhttps://arxiv.org/abs/1710.06642\n\n\n\n\n\n","category":"method"},{"location":"api/#RunStatistics.Partition","page":"API","title":"RunStatistics.Partition","text":"Partition(n::Int, k::Int, h::Int, c::Vector{Int}, y::Vector{Int})\n\nExpress the integer partition of n into k parts in the multiplicity representation with  n = \\sum_{i=2}^(h + 1) c_i * y_i. \n\n(see https://en.wikipedia.org/wiki/Partition(numbertheory))\n\nh is the number of distinct parts, y an array containing the distinct parts and c an  array containing their multiplicities.\n\nNOTE: due to the computation of subsequent partitions with the algorithm used in next_partition!()  the arrays y and c only hold relevant  values for the indices [2, h + 1] \n\nWhen reading a partition: ignore the first element of c and y and do not read beyond  c[h + 1], y[h + 1]!\n\n\n\n\n\n","category":"type"},{"location":"api/#RunStatistics.Delta","page":"API","title":"RunStatistics.Delta","text":"Delta(T_obs::Real, Nl::Integer, Nr::Integer, [epsrel::Nothing, epsabs::::Union{Real, Nothing}])\n\nCompute the Δ(Tobs | Nl, N_r) term defined in equation (13) in \n\nFrederik Beaujean and Allen Caldwell. Is the bump significant? An axion-search example\n\nhttps://arxiv.org/abs/1710.06642\n\nThe calculation involves a 1D numerical integration using the quadgk() function with the  relative and absolute target precision epsrel and epsabs. If not specified, the default  values of quadgk() are used. See https://juliamath.github.io/QuadGK.jl/stable/ for documentation.\n\n\n\n\n\n","category":"function"},{"location":"api/#RunStatistics.H-Tuple{Real, Real, Integer}","page":"API","title":"RunStatistics.H","text":"H(a::Real, b::Real, N::Integer)\n\nCompute the cumulative of h() as defined in section II.A. in\n\nFrederik Beaujean and Allen Caldwell. Is the bump significant? An axion-search example\n\nhttps://arxiv.org/abs/1710.06642\n\n\n\n\n\n","category":"method"},{"location":"api/#RunStatistics.h-Tuple{Real, Integer}","page":"API","title":"RunStatistics.h","text":"h(chisq::Real, N::Integer)\n\nCompute the probability density h(χ2 | Nr) for the right-hand side of a boundary spanning  run to be above expectation;  as explained in section II.A. in the paper below.\n\nCalculate it as the sum of probability densities for runs of different length times the χ2      probability for that number of degrees of freedom.\n\nImplements the term defined in equation (8) in \n\nFrederik Beaujean and Allen Caldwell. Is the bump significant? An axion-search example\n\nhttps://arxiv.org/abs/1710.06642\n\n\n\n\n\n","category":"method"},{"location":"api/#RunStatistics.init_partition-Tuple{Integer, Integer}","page":"API","title":"RunStatistics.init_partition","text":"init_partition(n::Int, k::Int)\n\nInitiate the first partition of an integer n into k parts; arguments must satisfy 0 < k <= n.  Returns an object of type Partition.\n\nThe elements in y[1] and c[1], of the arrays y and c containing the distinct parts and their  multiplicities, are buffer values needed for the computation of the next partition  in next_partition!().\n\nWhen reading a partition: ignore the first element of c and y and do not read beyond c[h + 1],  y[h + 1]: n = \\sum_{i=2}^(h + 1) c_i * y_i.\n\n\n\n\n\n","category":"method"},{"location":"api/#RunStatistics.next_partition!-Tuple{RunStatistics.Partition}","page":"API","title":"RunStatistics.next_partition!","text":"next_partition!(p::Partition)\n\nCompute the next partition of p, using a modified version of Algorithm Z from A. Zoghbi: Algorithms  for generating integer partitions, Ottawa (1993), https://www.ruor.uottawa.ca/handle/10393/6506. \n\nThe partition p is updated in place, saving memory.  Returns a boolean corresponding to whether the final partition has been reached. \n\n\n\n\n\n","category":"method"},{"location":"api/#RunStatistics.squares_cdf-Tuple{Real, Integer}","page":"API","title":"RunStatistics.squares_cdf","text":"squares_cdf(T_obs::Real, N::Integer)\n\nCompute P(T < Tobs | N), the value of the cumulative distribution of the Squares statistic T at the  value `Tobsobserved inN` independent trials with gaussian probability.\n\nT_obs is the value of the test statistic for the observed data set; i.e., the largest χ^2 of  any run of consecutive observed values above the expectation in a sequence of N independent trials  with Gaussian uncertainty. \n\nN is the total number of data points.\n\nThe calculation implements equations (16) and (17) from \n\nFrederik Beaujean and Allen Caldwell. A Test Statistic for Weighted Runs. Journal of Statistical Planning and Inference 141, no. 11 (November 2011): 3437–46. doi:10.1016/j.jspi.2011.04.022\n\nhttps://arxiv.org/abs/1005.3233.\n\n\n\n\n\n","category":"method"},{"location":"api/#RunStatistics.squares_cdf_approx","page":"API","title":"RunStatistics.squares_cdf_approx","text":"squarescdfapprox(T_obs::Real, L::Integer, [epsp::Real])\n\nCompute an approximation of P(T < T_obs | L = n * N), the value of the cumulative distribution  function for the Squares test statistic at T_obs,  the value of the Squares statistic observed in the data.  The total number of datapoints is L = n * N, if not defined otherwise, the function chooses the default values N = 80 and n = L / N.\n\nTo specify a certain choice for N and n, do:\n\nsquares_cdf_approx(T_obs::Real,  Ns::AbstractArray, epsp::Real = 0)\n\nWith Ns being an array holding N::Integer and n::Real as its first and second element: Ns = [N, n].\n\nThe accuracy's lower bound is n * 10^(-14), a desired accuracy up to this boundary can be specified with the optional epsp argument. See documentation on Accuracy under Guide/Details of computation.\n\nThis function implements equation (17) from:\n\nFrederik Beaujean and Allen Caldwell. Is the bump significant? An axion-search example\n\nhttps://arxiv.org/abs/1710.06642\n\n\n\n\n\n","category":"function"},{"location":"api/#RunStatistics.squares_pvalue-Tuple{Real, Integer}","page":"API","title":"RunStatistics.squares_pvalue","text":"squares_pvalue(T_obs::Real, N::Integer)\n\nCompute P(T >= T_obs | N), the p value for the Squares test statistic T being larger or equal to T_obs,  the value of the Squares statistic observed in N datapoints. \n\nThe Squares statistic T denotes the largest χ^2 of any run of consecutive successes (above expectation) in a  sequence of N independent trials with Gaussian uncertainty.\n\nVia squares_cdf() this function implements equations (16) and (17) from\n\nFrederik Beaujean and Allen Caldwell. A Test Statistic for Weighted Runs. Journal of Statistical Planning and Inference 141, no. 11 (November 2011): 3437–46. doi:10.1016/j.jspi.2011.04.022\n\nhttps://arxiv.org/abs/1005.3233.\n\n\n\n\n\n","category":"method"},{"location":"api/#RunStatistics.squares_pvalue_approx","page":"API","title":"RunStatistics.squares_pvalue_approx","text":"squares_pvalue_approx(T_obs::Real, L::Integer, [epsp::Real])\n\nCompute an approximation of P(T >= T_obs | L), the p value for the Squares test  statistic T being larger or equal to T_obs,  the value of the Squares statistic observed in the data.  The total number of datapoints is L = n * N, if not defined otherwise, the function chooses the default values N = 80 and n = L / N.\n\nTo specify a certain choice for N and n, do:\n\nsquares_pvalue_approx(T_obs::Real, Ns::AbstractArray,  [epsp::Real])\n\nWith Ns being an array holding N::Integer and n::Real as its first and second element: Ns = [N, n]\n\nThe accuracy's lower bound is n * 10^(-14), a desired accuracy up to this boundary can be specified with the optional epsp argument. See documentation on Accuracy under Guide/Details of computation.\n\nVia squares_cdf_approx() this function implements equation (17) from:\n\nFrederik Beaujean and Allen Caldwell. Is the bump significant? An axion-search example\n\nhttps://arxiv.org/abs/1710.06642\n\n\n\n\n\n","category":"function"},{"location":"api/#RunStatistics.t_obs-Tuple{AbstractArray, Real, Real}","page":"API","title":"RunStatistics.t_obs","text":"t_obs(X::AbstractArray, μ::Real, σ2::Real)\n\nCompute the value of the Squares test statistic T_obs i.e. the largest χ2 of any run of consecutive successes (above expectation) in a sequence of N independent trials with Gaussian uncertainty. μ and σ2 are the expectation and variance of the observations.\n\nFind the location(s) of the run(s) that produces T_obs.\n\nReturns a tuple containing T_obs and one or more arrays containing the indices of the runs that produce T_obs.\n\nFor the Squares statistic to be calculable, the observed data must satisfy following conditions:\n\n    All observations {X_i} are independent. \n    Each observation is normally distributed, X_i ∼ N( µ_i, σ^2_i ).\n    Mean µ_i and variance σ^2_i are known.\n\nIn case the observations {X_i} have individual expectations and variances, use:\n\nt_obs(X::AbstractArray, μ::AbstractArray, σ2::AbstractArray)\n\nWith μ[i] and σ2[i] being the mean and variance of the i-th element of X. \n\nSee:\n\nFrederik Beaujean and Allen Caldwell. A Test Statistic for Weighted Runs. Journal of Statistical Planning and Inference 141, no. 11 (November 2011): 3437–46. \n\nhttps://www.sciencedirect.com/science/article/abs/pii/S0378375811001935?via%3Dihub\n\nhttps://arxiv.org/abs/1005.3233\n\n\n\n\n\n","category":"method"},{"location":"introduction/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"This page provides a summarized explanation for the Squares test statistic T and when and in what context it can be used. For a comprehensive derivation and explanation see [1] and [2].","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Pages = [\"introduction.md\"]\nDepth = 3","category":"page"},{"location":"introduction/#Motivation","page":"Introduction","title":"Motivation","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"One of the most common tasks in scientific inference is comparing observations and model predictions. Based on this comparison, the hypothesized model may be either accepted or rejected. In the latter case usually an improved model is sought. The comparison between observations and the new model is then repeated until a satisfactory model has been constructed.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"In model validation the goal is to provide quantitative test procedures. The standard approach consists of defining a scalar function of the data D, called test statistic T (D), such that a large value of T indicates a large deviation of the data from the expectations under the hypothesized model mathcalH. Correspondingly, small T is seen as good agreement.","category":"page"},{"location":"introduction/#The-Squares-test-statistic","page":"Introduction","title":"The Squares test statistic","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The Squares test statistic or Squares statistic for short, in the following denoted with T, is a test statistic sensitive to local deviations of the data from expectations within an ordered data set[1].","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"It supplements the classic chi^2 test which ignores the ordering of observations and provides additional sensitivity to local deviations from expectations. ","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The Squares statistic T can be defined for data that follows any symmetric distribution[1], but in this package only data with a gaussian probability distribution is considered:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"beginalign\nX_i sim mathcalN(mu_i sigma_i^2)\nendalign","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The hypothesis mathcalH for the data is:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"All observations X_i are independent. \nEach observation is normally distributed, X_i sim mathcalN(mu_i sigma^2_i)\nMean mu_i and variance sigma^2_i are known.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"T is based on runs of weighted deviations from a mean value, observed in samples X_i from independent normal distributions. ","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"A run in this context refers to a sequence of observations that share a common attribute commonly called a success. Here an observation is called a success, S, if the observed value exceeds the expected value. Similarly, an expected value exceeding the observation is considered a failure, F.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"T is formally defined via:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Split the data X_i into runs. Keep the success runs and ignore the   failure runs. Denote by A_j = X_j_1 X_j_2  the set of    observations in the j-th success run.\nAssociate a weight omega(A_j) with each success run:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"beginalign\nomega(A_j) equiv chi_runj^2 = displaystylesum_ifrac(X_i-mu_i)^2sigma_i^2\nendalign","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Choose T as the largest weight of any run in the entire sequence of observed data:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"beginalign\nT equiv max_j omega(A_j)\nendalign","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Note that the choice for the weight omega(A_j) implemented in this package is only one of the most significant ones, more general options are available (see section 1. of [1]).","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Consider for example an observed data sequence of: ","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"SSSFFSFFFSSF ","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"where S denotes a success, a value above the expected value, and F a failure. In accordance with the above steps, only the success runs are considered:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"underbracemathbfSSS_A_1FFunderbracemathbfS_A_2FFFunderbracemathbfSS_A_3F ","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"For each of the three success runs A_j observed in this example, the weight omega(A_j)=chi_runj^2 is calculated. The value T_obs, denoting the observed value of T in this sequence of data is then the maximum of the three weights T_obs = max_j omega(A_j).","category":"page"},{"location":"introduction/#Interpreting-the-Squares-statistic","page":"Introduction","title":"Interpreting the Squares statistic","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"To facilitate the interpretation of T (how large is too large?), it is useful to introduce the p-value p. Assuming mathcalH, the p-value is defined as the tail area probability to randomly sample a value of T larger than or equal to T_obs, the value of T observed in the data:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"beginalign\np equiv P (T  T_obs  mathcalH) \nendalign","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"If mathcalH is correct and all parameters are fixed, then p is a random variable with uniform distribution on 0 1. An incorrect model will typically yield smaller values of p.","category":"page"},{"location":"introduction/#Approximation-for-large-numbers-of-observations","page":"Introduction","title":"Approximation for large numbers of observations","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The cost for calculating the exact p-value for the Squares statistic as described in the initial paper[1], scales with the number N of observations in a sequence of data like expN^frac12N and quickly grows too large for N gtrsim 80. ","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The authors derived an approximation for large numbers of data in the follow-up paper[2].","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The underlying principle is to split the (long) total sequence of observed data into shorter sequences, for which the p-value can be computed exactly. An approximate p-value p for the entire observed data sequence can then be extrapolated. The approximation is constructed to have high accuracy in the region of interest, for small values for p. ","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"For a comprehensive explanation see section II. of [2].","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"[1]: Frederik Beaujean and Allen Caldwell. A Test Statistic for Weighted Runs. Journal of Statistical Planning and Inference 141, no. 11 (November 2011): 3437–46. doi:10.1016/j.jspi.2011.04.022 arXiv:1005.3233","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"[2]: Frederik Beaujean and Allen Caldwell. Is the bump significant? An axion-search example arXiv:1710.06642","category":"page"},{"location":"LICENSE/#LICENSE","page":"LICENSE","title":"LICENSE","text":"","category":"section"},{"location":"LICENSE/","page":"LICENSE","title":"LICENSE","text":"using Markdown\nMarkdown.parse_file(joinpath(@__DIR__, \"..\", \"..\", \"LICENSE.md\"))","category":"page"},{"location":"#RunStatistics.jl","page":"Home","title":"RunStatistics.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A package implementing the exact evaluation of the cumulative distribution function of the Squares test statistic T as defined in ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Frederik Beaujean and Allen Caldwell. A Test Statistic for Weighted Runs. doi:10.1016/j.jspi.2011.04.022 arXiv:1005.3233","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package also includes an implementation of an approximation of this cumulative for the more general case of large numbers of observations, as derived in ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Frederik Beaujean and Allen Caldwell. Is the bump significant? An axion-search example arXiv:1710.06642","category":"page"},{"location":"","page":"Home","title":"Home","text":"This code is based on the original implementation by Frederik Beaujean in c++ and mathematica.","category":"page"},{"location":"#Package-Features","page":"Home","title":"Package Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Calculate the p-value for the Squares test statistic[1] T observed in N independent trials of gaussian uncertainty\nImproved performance and readability over the original implementation thanks to Julia \nInbuilt implementation for generating integer partitions of an integer n into k parts","category":"page"},{"location":"#Manual-Outline","page":"Home","title":"Manual Outline","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"introduction.md\",\"guide.md\"]\nDepth = 3","category":"page"},{"location":"","page":"Home","title":"Home","text":"[1]: Frederik Beaujean and Allen Caldwell. A Test Statistic for Weighted Runs. Journal of Statistical Planning and Inference 141, no. 11 (November 2011): 3437–46. doi:10.1016/j.jspi.2011.04.022 arXiv:1005.3233","category":"page"},{"location":"#Citing-RunStatistic.jl","page":"Home","title":"Citing RunStatistic.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"When using RunStatistics.jl for research, teaching or similar, please cite the original authors' work:","category":"page"},{"location":"","page":"Home","title":"Home","text":"@article{beaujean2011test,\n  title={A test statistic for weighted runs},\n  author={Beaujean, Frederik and Caldwell, Allen},\n  journal={Journal of Statistical Planning and Inference},\n  volume={141},\n  number={11},\n  pages={3437--3446},\n  year={2011},\n  publisher={Elsevier}\n}\n\n@article{Beaujean:2017eyq,\n  author         = \"Beaujean, Frederik and Caldwell, Allen and Reimann, Olaf\",\n  title          = \"{Is the bump significant? An axion-search example}\",\n  year           = \"2017\",\n  eprint         = \"1710.06642\",\n  archivePrefix  = \"arXiv\",\n  primaryClass   = \"hep-ex\",\n  SLACcitation   = \"%%CITATION = ARXIV:1710.06642;%%\"\n}","category":"page"}]
}
